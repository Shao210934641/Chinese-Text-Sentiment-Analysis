{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDHsgmglqD8U"
      },
      "source": [
        "# Chinese Text Sentiment Analysis Based on Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***Label:***"
      ],
      "metadata": {
        "id": "UmV877bG0FJc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$positive->label('美味')=1$$\n",
        "$$negative->label('难吃')=0$$"
      ],
      "metadata": {
        "id": "WVLgyBG5ea4E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***Flowchart:***\n",
        "<center><img width=500 src=\"https://i.imgur.com/Ln5oRY1.png\"></center>"
      ],
      "metadata": {
        "id": "NCNwvSMoczcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow==2.5.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6JoPI0tAmhb-",
        "outputId": "8e359dd1-e7fe-428a-82cb-dfc206645eda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.5.0\n",
            "  Downloading tensorflow-2.5.0-cp37-cp37m-manylinux2010_x86_64.whl (454.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 454.3 MB 17 kB/s \n",
            "\u001b[?25hCollecting gast==0.4.0\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (0.2.0)\n",
            "Collecting grpcio~=1.34.0\n",
            "  Downloading grpcio-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 41.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (3.1.0)\n",
            "Collecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 69.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.15.0)\n",
            "Collecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (0.37.1)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.1.2)\n",
            "Collecting numpy~=1.19.2\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 43.7 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
            "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 58.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (3.3.0)\n",
            "Collecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.6.3)\n",
            "Collecting keras-nightly~=2.5.0.dev\n",
            "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 50.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (3.17.3)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (2.8.0)\n",
            "Collecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow==2.5.0) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (0.6.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (3.2.0)\n",
            "Building wheels for collected packages: wrapt\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68722 sha256=aa01260d51f3103c0dece1e720c994d488904a18606231b31841e566fe0e8420\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "Successfully built wrapt\n",
            "Installing collected packages: typing-extensions, numpy, grpcio, absl-py, wrapt, tensorflow-estimator, keras-nightly, gast, flatbuffers, tensorflow\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.1.1\n",
            "    Uninstalling typing-extensions-4.1.1:\n",
            "      Successfully uninstalled typing-extensions-4.1.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.47.0\n",
            "    Uninstalling grpcio-1.47.0:\n",
            "      Successfully uninstalled grpcio-1.47.0\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.1.0\n",
            "    Uninstalling absl-py-1.1.0:\n",
            "      Successfully uninstalled absl-py-1.1.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220527125636\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220527125636:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220527125636\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed absl-py-0.15.0 flatbuffers-1.12 gast-0.4.0 grpcio-1.34.1 keras-nightly-2.5.0.dev2021032900 numpy-1.19.5 tensorflow-2.5.0 tensorflow-estimator-2.5.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "absl",
                  "flatbuffers",
                  "gast",
                  "grpc",
                  "keras",
                  "numpy",
                  "tensorflow",
                  "typing_extensions",
                  "wrapt"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install numpy==1.19.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_wLil_Soe9A",
        "outputId": "222a2e04-e544-4a53-ee24-78d87978a244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gensim==4.1.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ze285M2pKY4",
        "outputId": "6bff9d75-9352-48e1-ad5b-2839745c9610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gensim==4.1.2\n",
            "  Downloading gensim-4.1.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1 MB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==4.1.2) (5.2.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim==4.1.2) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==4.1.2) (1.7.3)\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy\n",
        "# numpy.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "JCa1Wb7VprJu",
        "outputId": "47965328-351e-406c-de2e-8ecde92c4b75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.19.5'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow\n",
        "# tensorflow.__version__ "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "86VdDy8NqPJ8",
        "outputId": "d0dbb3dd-d5b0-442a-d213-5afa6aeba2f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.5.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import gensim \n",
        "# gensim.__version__ "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "BCM4G-IfqUIU",
        "outputId": "3ecebeba-ba16-45c9-b381-af871e5a5cf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'4.1.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib\n",
        "# matplotlib.__version__ "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "r6N-Pw4hzntw",
        "outputId": "d7362f38-f024-4d84-caf1-bab5a9776376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.2.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "D1icdxS5HTuy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "f1titB04qD8W"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import jieba  # jieba: Chinese words segmentation module\n",
        "from gensim.models import KeyedVectors  # gensim: load the pre-trained word vector\n",
        "import warnings\n",
        "import os\n",
        "import random\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import bz2  # unzip\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "from sklearn.model_selection import train_test_split  # Split training and test samples\n",
        "# using tensorflow's keras interface\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, GRU, Embedding, LSTM, Bidirectional\n",
        "# from tensorflow.keras.layers import Dense, GRU, Embedding, LSTM, Bidirectional\n",
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Pre-trained Word Vectors Model\n",
        "###### In the word vector model, each word is an index, which corresponds to a vector of length 300. Since the LSTM neural network model does not directly process Chinese text, we need to first perform word separation operations and then convert the words into word vectors."
      ],
      "metadata": {
        "id": "rVw81P8gHc4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Place the downloaded word vectors in the embeddings folder in the root directory and unzip\n",
        "with open(\"embeddings/sgns.zhihu.bigram\", 'wb') as new_file, open(\"embeddings/sgns.zhihu.bigram.bz2\", 'rb') as file:\n",
        "    decompressor = bz2.BZ2Decompressor()\n",
        "    for data in iter(lambda : file.read(100 * 1024), b''):\n",
        "        new_file.write(decompressor.decompress(data))"
      ],
      "metadata": {
        "id": "tn8BuRvVv_J1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zoMND5sqqD8Y"
      },
      "outputs": [],
      "source": [
        "# Load pre-trained Chinese word separation embedding using gensim \n",
        "cn_model = KeyedVectors.load_word2vec_format('embeddings/sgns.zhihu.bigram', binary=False, unicode_errors=\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DPP3p0Y2qD8Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "269fb944-aa80-4c7d-889f-6ff10648558f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of the word vector is 300\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 8.375510e-01,  4.208510e-01, -2.799180e-01,  5.622690e-01,\n",
              "       -8.997970e-01,  5.272690e-01,  9.496400e-01,  4.563700e-02,\n",
              "       -9.810400e-02, -2.630750e-01, -1.524345e+00,  7.652050e-01,\n",
              "       -1.986810e-01, -6.065320e-01,  5.041090e-01, -4.938500e-01,\n",
              "        5.872340e-01, -1.234050e-01, -4.244760e-01,  1.889090e-01,\n",
              "        7.961510e-01,  6.705470e-01,  7.920700e-02,  5.041190e-01,\n",
              "       -5.473530e-01, -6.844260e-01,  4.471700e-01, -2.957340e-01,\n",
              "       -2.229900e-01,  1.689930e-01,  3.720270e-01, -1.595700e-01,\n",
              "       -3.491800e-02,  2.385590e-01, -2.851160e-01, -3.496570e-01,\n",
              "       -2.146670e-01,  1.279030e-01,  1.851230e-01, -8.933700e-02,\n",
              "       -3.738830e-01, -3.261810e-01,  8.310600e-02, -2.764490e-01,\n",
              "        1.571830e-01, -6.430000e-03, -4.535830e-01,  3.596070e-01,\n",
              "       -4.212470e-01,  4.759860e-01,  1.874830e-01, -1.392510e-01,\n",
              "       -6.330000e-04,  1.503450e-01, -2.699750e-01, -3.896300e-02,\n",
              "       -9.544230e-01,  1.075360e-01, -5.690130e-01,  5.670360e-01,\n",
              "       -4.811400e-02,  6.133300e-01, -4.539180e-01, -5.689090e-01,\n",
              "        2.896540e-01,  6.357770e-01, -2.847990e-01,  7.098020e-01,\n",
              "        1.086606e+00, -3.694120e-01,  3.299900e-01,  3.011870e-01,\n",
              "       -4.837610e-01, -7.841770e-01,  2.162470e-01, -5.330670e-01,\n",
              "       -2.891000e-02,  3.623100e-02,  2.827150e-01,  6.735050e-01,\n",
              "        2.663360e-01,  9.530600e-02, -1.996720e-01, -6.727900e-02,\n",
              "       -1.855300e-02,  7.735000e-02, -5.930880e-01,  1.460950e-01,\n",
              "        1.235320e-01, -3.692230e-01,  3.521490e-01,  8.259170e-01,\n",
              "        4.163100e-02, -3.422400e-01, -2.160140e-01, -2.257000e-02,\n",
              "       -4.426690e-01, -5.237380e-01,  9.769520e-01,  9.761100e-02,\n",
              "        8.131600e-02,  1.249865e+00, -1.347290e-01, -4.944500e-02,\n",
              "        2.450660e-01, -9.516100e-02, -1.373600e-02,  2.589440e-01,\n",
              "       -2.307450e-01, -7.396090e-01, -1.387310e-01,  7.707160e-01,\n",
              "       -6.306910e-01, -7.997900e-02, -7.441800e-01,  5.895290e-01,\n",
              "       -8.884930e-01,  1.185760e-01, -4.050990e-01, -3.021340e-01,\n",
              "        5.811800e-01,  6.649350e-01,  1.378750e-01,  6.397900e-02,\n",
              "        9.010100e-02, -6.142100e-01,  3.680520e-01, -3.308950e-01,\n",
              "       -7.009300e-02, -3.792380e-01,  9.101310e-01,  6.782200e-02,\n",
              "       -5.490720e-01,  1.292290e-01,  1.560590e-01,  2.469130e-01,\n",
              "       -5.391900e-02,  3.840380e-01,  1.894790e-01,  2.606600e-02,\n",
              "       -6.332170e-01,  2.573600e-01,  1.967280e-01, -8.227460e-01,\n",
              "       -4.288110e-01, -3.262770e-01,  6.877430e-01,  7.053550e-01,\n",
              "       -8.101400e-02, -2.334680e-01,  6.219800e-02, -6.362430e-01,\n",
              "        1.933110e-01,  3.480220e-01,  4.008860e-01, -9.878700e-02,\n",
              "        1.902100e-01, -3.564020e-01, -1.772870e-01,  5.465770e-01,\n",
              "        2.861030e-01,  7.473600e-02, -4.498400e-01, -3.510960e-01,\n",
              "        4.962360e-01,  6.738700e-02, -9.542230e-01,  7.612400e-02,\n",
              "        1.124004e+00,  5.694360e-01, -1.693910e-01,  4.307700e-02,\n",
              "        1.049010e-01,  1.350860e-01, -2.019580e-01, -5.534500e-01,\n",
              "       -1.015365e+00,  1.169792e+00,  2.502820e-01,  1.975950e-01,\n",
              "       -6.416950e-01, -9.712700e-02,  5.445690e-01,  4.815240e-01,\n",
              "        6.051380e-01, -3.225670e-01, -5.030960e-01, -2.280690e-01,\n",
              "        5.468290e-01,  2.893320e-01, -4.626020e-01, -3.185000e-03,\n",
              "       -1.628060e-01, -1.683900e-01,  9.449500e-02, -6.396950e-01,\n",
              "        1.432850e-01, -1.008660e-01, -4.234660e-01,  3.131530e-01,\n",
              "        6.932200e-02,  1.691740e-01, -6.164500e-02, -7.792600e-01,\n",
              "        3.817640e-01, -2.610030e-01, -1.162530e-01,  6.449400e-02,\n",
              "       -8.123460e-01,  4.360900e-02, -4.961360e-01,  7.157490e-01,\n",
              "       -6.938460e-01,  2.178750e-01,  2.582620e-01,  3.909510e-01,\n",
              "        3.011010e-01,  9.815600e-02,  5.126400e-02,  7.179400e-01,\n",
              "        1.062510e-01,  4.506820e-01, -1.385290e-01, -7.843030e-01,\n",
              "       -1.643300e-02, -5.120510e-01,  7.013410e-01,  5.648950e-01,\n",
              "        1.832710e-01, -7.574150e-01, -4.377600e-01, -1.664640e-01,\n",
              "        1.199600e-01,  4.446600e-02, -7.481300e-01, -2.840190e-01,\n",
              "        3.475090e-01,  5.801960e-01,  2.461120e-01,  6.150700e-02,\n",
              "       -8.927140e-01, -6.825900e-02,  1.268098e+00,  1.025260e-01,\n",
              "        2.198650e-01, -4.548420e-01,  3.467400e-02,  1.387800e-01,\n",
              "        2.152560e-01, -1.520000e-04,  2.521600e-01, -5.611600e-02,\n",
              "        3.989510e-01, -4.545040e-01, -2.425520e-01,  1.634460e-01,\n",
              "       -8.490120e-01, -4.628340e-01,  1.050020e-01,  2.127820e-01,\n",
              "       -3.832050e-01, -1.274690e-01, -8.635690e-01,  9.936300e-02,\n",
              "       -3.554690e-01, -3.905850e-01,  1.786530e-01, -1.026720e-01,\n",
              "       -7.065050e-01,  8.223400e-02, -5.151900e-02, -9.509600e-02,\n",
              "       -3.977860e-01,  3.936270e-01,  3.537000e-03, -1.108840e-01,\n",
              "       -2.185610e-01, -2.296720e-01, -5.608100e-01, -5.568920e-01,\n",
              "       -5.222500e-02,  6.378300e-02,  5.635820e-01, -7.782280e-01,\n",
              "        5.836800e-01,  9.342290e-01, -4.287300e-02,  1.383850e-01,\n",
              "       -4.206350e-01,  2.797510e-01, -2.255450e-01,  2.723170e-01,\n",
              "       -6.376710e-01, -4.352860e-01, -9.615850e-01, -2.727510e-01,\n",
              "       -5.851680e-01,  1.902460e-01,  3.606010e-01, -8.082410e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Input a Chinese word and output a vector of words of length 300\n",
        "embedding_dim = cn_model['青岛'].shape[0]\n",
        "print('The length of the word vector is {}'.format(embedding_dim))\n",
        "cn_model['青岛']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BJbNCXmPqD8a",
        "outputId": "25d5e99e-241c-40b4-929d-08b5125a7a3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.55973804"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Calculate the cosine similarity of two words \n",
        "cn_model.similarity('英国', '伦敦')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0MDlzj5iqD8a",
        "outputId": "d3cd00ae-b52c-4b47-f63a-fdfe5726edfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('美元', 0.7081582546234131),\n",
              " ('港币', 0.6911839842796326),\n",
              " ('日元', 0.6810632348060608),\n",
              " ('汇率', 0.679571270942688),\n",
              " ('欧元', 0.6542581915855408),\n",
              " ('欧元和', 0.6420362591743469),\n",
              " ('英镑', 0.6394895911216736),\n",
              " ('贬值', 0.636674165725708),\n",
              " ('韩元', 0.6353235840797424),\n",
              " ('卢布', 0.6327826976776123)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Input a Chinese word and find the 10 most similar words to it \n",
        "cn_model.most_similar(positive=['人民币'], topn=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5O6aB9vYqD8a",
        "outputId": "45fe9760-253b-4b39-b31b-73c7cd9a164d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In [英国 德国 法国 中国 帅哥]:\n",
            "The word that is not in the same category is: 帅哥\n"
          ]
        }
      ],
      "source": [
        "# Enter a set of Chinese words and find the word that is not in the same category\n",
        "test_words = '英国 德国 法国 中国 帅哥'\n",
        "test_words_result = cn_model.doesnt_match(test_words.split())\n",
        "print('In '+ '['+test_words+']' +':\\nThe word that is not in the same category is: %s' %test_words_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGdgVx_6qD8b"
      },
      "source": [
        "**datasets**  \n",
        "The datasets are placed in two separate .txt files: \n",
        "* <I>positive_samples.txt</I> (2000 Chinese positive reviews, label=1）\n",
        "* <I>negative_samples.txt</I> (2000 Chinese negative reviews, label=0）"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing "
      ],
      "metadata": {
        "id": "FBPtvFaLHxmU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6tktc_wiqD8c"
      },
      "outputs": [],
      "source": [
        "train_texts_orig = []  # Store all reviews, one string per case\n",
        "train_target = []  # Store all labels. The first 2,000 reviews are positive, the last 2,000 are negative. \n",
        "with open(\"datasets/positive_samples.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "        dic = eval(line)\n",
        "        train_texts_orig.append(dic[\"text\"])\n",
        "        train_target.append(dic[\"label\"])\n",
        "\n",
        "with open(\"datasets/negative_samples.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "        dic = eval(line)\n",
        "        train_texts_orig.append(dic[\"text\"])\n",
        "        train_target.append(dic[\"label\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "XP_r6sKdqD8c",
        "outputId": "918cbbb1-639f-40b3-9c12-84e8ef35a6d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4000\n",
            "4000\n"
          ]
        }
      ],
      "source": [
        "print(len(train_texts_orig))\n",
        "print(len(train_target))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6qoPFriqD8d"
      },
      "source": [
        "**remove punctuation, jieba word segmentation and tokenize**  \n",
        "* First we remove the punctuation from each sample. \n",
        "* Then using jieba word segmentation, which returns a generator -> cut. \n",
        "* However, the generator cannot be tokenized directly, so we also need to convert it to a list -> cut_list. \n",
        "* Next, Index it. \n",
        "* Finally, the text evaluated in each case becomes a segment of indexed numbers corresponding to the words in the pre-trained word vectors model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yebbnJxLqD8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "593516f8-5202-4225-ccf5-ac0496913ff9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 1.048 seconds.\n",
            "Prefix dict has been built successfully.\n"
          ]
        }
      ],
      "source": [
        "train_tokens = []\n",
        "for text in train_texts_orig:\n",
        "    # Remove punctuation\n",
        "    text = re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&*（）]+\", \"\",text)\n",
        "    # jieba word segmentation\n",
        "    cut = jieba.cut(text)  # jieba's output is a generator -> cut\n",
        "    cut_list = [ i for i in cut ]  # Convert the generator to list -> cut_list \n",
        "    for i, word in enumerate(cut_list):\n",
        "        try:\n",
        "            cut_list[i] = cn_model.key_to_index[word]  # Convert words to index\n",
        "            # cut_list[i] = cn_model.vocab[word].index\n",
        "        except KeyError:\n",
        "            cut_list[i] = 0  # If the word is not in the dictionary, output 0\n",
        "    train_tokens.append(cut_list)  # train_tokens is a long list containing 4000 small lists, corresponding to each evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BifCDXh_qD8d"
      },
      "source": [
        "**normalising index length**  \n",
        "Because each review is of a different length, it would be a waste of computing resources to simply take the longest one and fill the others to the same length, so we take a compromise length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XmTm_YJRqD8d"
      },
      "outputs": [],
      "source": [
        "# Get lengths of all tokens\n",
        "num_tokens = [ len(tokens) for tokens in train_tokens ]\n",
        "num_tokens = np.array(num_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "2c8XtwTBqD8e",
        "outputId": "185a9615-ca6e-491f-f763-4a0c1aa80948",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71.42575"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# The average length of tokens\n",
        "np.mean(num_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wm7wIO5PqD8e",
        "outputId": "9713cf94-c1c1-4537-94f5-1e41d04c327c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1540"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# The longest tokens length\n",
        "np.max(num_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1dDtvqirqD8e",
        "outputId": "6763170c-84de-4369-a5fc-c542c5de27d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Display the distribution of tokens length \n",
        "plt.hist(np.log(num_tokens), bins = 100)\n",
        "plt.xlim((0,10))\n",
        "plt.ylabel('number of tokens')\n",
        "plt.xlabel('length of tokens')\n",
        "plt.title('Distribution of tokens length')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Y0G70gx1qD8f",
        "outputId": "56cb72a3-c8f6-4ce3-8ac4-2e943e8e3c6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "236"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# Take the mean of tokens + standard deviation of tokens *2. The distribution of tokens lengths is approximated as a normal distribution\n",
        "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
        "max_tokens = int(max_tokens)\n",
        "max_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "63mGmdP-qD8f",
        "outputId": "f9dde3a3-f1b1-406f-9631-5e19d715f0e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9565"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# When tokens are taken to be 236 in length, about 95% of the sample is covered. \n",
        "# (Under-length tokens will be padding and over-length tokens will be trimmed later)\n",
        "np.sum( num_tokens < max_tokens ) / len(num_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6rQAiWmqD8f"
      },
      "source": [
        "**reverse tokenize**  \n",
        "Define a function to convert the index into readable text, which is important for debugging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "1tZ0_f5CqD8f"
      },
      "outputs": [],
      "source": [
        "# Convert tokens to text\n",
        "def reverse_tokens(tokens):\n",
        "    text = ''\n",
        "    for i in tokens:\n",
        "        if i != 0:\n",
        "            # text = text + cn_model.index2word[i]\n",
        "            text = text + cn_model.index_to_key[i]\n",
        "        else:\n",
        "            text = text + ' '\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "zCRvjZ75qD8g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "b92c4fd4-e635-4812-afa7-62a6d44376a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'早餐太差无论去多少人那边也不加食品的酒店应该重视一下这个问题了房间本身很好'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# After tokenize and revert to text, the punctuation is gone\n",
        "reverse = reverse_tokens(train_tokens[0])\n",
        "reverse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "pafagz2TqD8g",
        "outputId": "ab0ab8fc-f15f-4432-efd1-cd73b86bd449",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'早餐太差，无论去多少人，那边也不加食品的。酒店应该重视一下这个问题了。\\n\\n房间本身很好。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# original text\n",
        "train_texts_orig[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the Embedding Matrix "
      ],
      "metadata": {
        "id": "46SjJzasIGD1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhSQX7a7qD8h"
      },
      "source": [
        "**create the embedding matrix**  \n",
        "* Now, we need to create an embedding matrix. According to keras, we need to prepare a dimension of $(numwords, embedddingdim)$ of the matrix, where numwords represents the number of words we use, and emdeddingdim is 300 in the pre-trained word vector model we are using now, with each word represented by a vector of length 300.\n",
        "* Note that we use only the first 50k most frequently used words. There are 2.6 million words in this pre-trained word vector model, and it would be a waste of computational resources to use them all for the classification problem.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "HIe1dxTyqD8h",
        "outputId": "e2fde681-1ddb-4d49-c4ba-807f43c05ee6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "embedding_dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ubuNjcfCqD8h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6f554a8-9c7f-45a8-bfcc-027fa0290f79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension of embedding_matrix: (50000, 300)\n"
          ]
        }
      ],
      "source": [
        "num_words = 50000  # Use only the first 50,000 words\n",
        "embedding_matrix = np.zeros((num_words, embedding_dim))  # Initialise embedding_matrix\n",
        "for i in range(num_words):\n",
        "    embedding_matrix[i,:] = cn_model[cn_model.index_to_key[i]]\n",
        "    # embedding_matrix[i,:] = cn_model[cn_model.index2word[i]]\n",
        "embedding_matrix = embedding_matrix.astype('float32')  # embedding_matrix is a matrix of [num_words, embedding_dim]. \n",
        "print('Dimension of embedding_matrix:', embedding_matrix.shape)  # Dimension of embedding_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDojFDN6qD8i"
      },
      "source": [
        "**padding and truncating**  \n",
        "After we convert the text into indexes, the length of each string of indexes is not equal, so in order to facilitate the training of the model, we need to normalise the length of the indexes. Above, we have chosen 236 samples, which can cover 95% of the length of the training samples.  \n",
        "Next, we do padding and truncating. We generally use the 'pre' method, which will fill in the front of the text indexes with 0. Because, according to some research materials in practice, if you fill in the text indexes after 0, it will have some adverse effects on the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "2gd0fpAwqD8i"
      },
      "outputs": [],
      "source": [
        "# Padding and truncating. The input train_tokens is a list, and the returned train_pad is a numpy array. \n",
        "train_pad = pad_sequences(train_tokens, maxlen=max_tokens,\n",
        "                            padding='pre', truncating='pre')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "jUckArrrqD8i"
      },
      "outputs": [],
      "source": [
        "# Words beyond the 50,000 word vector are replaced by 0\n",
        "train_pad[ train_pad>=num_words ] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "YZVwlTZjqD8i",
        "outputId": "bf41c3b8-c511-476e-9a82-3e3a77436780",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "         290,  3053,    57,   169,    73,     1,    25, 11216,    49,\n",
              "         163, 15985,     0,     0,    30,     8,     0,     1,   228,\n",
              "         223,    40,    35,   653,     0,     5,  1642,    29, 11216,\n",
              "        2751,   500,    98,    30,  3159,  2225,  2146,   371,  6285,\n",
              "         169, 27396,     1,  1191,  5432,  1080, 20055,    57,   562,\n",
              "           1, 22671,    40,    35,   169,  2567,     0, 42665,  7761,\n",
              "         110,     0,     0, 41281,     0,   110,     0, 35891,   110,\n",
              "           0, 28781,    57,   169,  1419,     1, 11670,     0, 19470,\n",
              "           1,     0,     0,   169, 35071,    40,   562,    35, 12398,\n",
              "         657,  4857], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# Fill in the front of the text index with 0. Text at the end\n",
        "train_pad[33]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "-Rbp1zX1qD8j"
      },
      "outputs": [],
      "source": [
        "# create target labels, 1 for the first 2000 samples, 0 for the next 2000\n",
        "train_target = np.array(train_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "I6cFcpv8qD8j"
      },
      "outputs": [],
      "source": [
        "# 90% for training, 10% for test\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_pad, train_target, test_size=0.1, random_state=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Building "
      ],
      "metadata": {
        "id": "uTDWSQICHN7d"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdSsCmJJqD8k"
      },
      "source": [
        "Now we build the LSTM model using keras. The first layer of the model is the embedding layer, and only after we have transformed the token index into a word vector matrix can the text be processed by the neural network. Keras provides an embedding interface to avoid tedious sparse matrix operations.   \n",
        "The matrix entered in the Embedding layer is: $$(batchsize, maxtokens)$$\n",
        "The output matrix is: $$(batchsize, maxtokens, embeddingdim)$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "zXxMebE0qD8k"
      },
      "outputs": [],
      "source": [
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "H05FWesfqD8k"
      },
      "outputs": [],
      "source": [
        "# The first layer of the model is embedding\n",
        "model.add(Embedding(num_words,\n",
        "                    embedding_dim,\n",
        "                    weights=[embedding_matrix],\n",
        "                    input_length=max_tokens,\n",
        "                    trainable=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Knl_DEIpqD8m"
      },
      "outputs": [],
      "source": [
        "# 有兴趣的同学可以调整一下模型参数, 看看会不会有更好的结果\n",
        "model.add(Bidirectional(LSTM(units=64, return_sequences=True)))\n",
        "model.add(LSTM(units=32, return_sequences=True))\n",
        "model.add(LSTM(units=16, return_sequences=False)) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQlyH9mNqD8m"
      },
      "source": [
        "We tried several neural network structures, and because the training samples were relatively small, the training process did not take long to complete.\n",
        "* GRU: The test samples could achieve 87% accuracy if GRU was used. However, when I tested my own text content, I found that the output of the last layer of the GRU activation function was all around 0.5, indicating that the model's judgement was not very clear, and after testing, I found that the model sometimes missed the judgement for negative sentences. We would expect the output to be close to 0 for negative samples and close to 1 for positive samples rather than hovering between 0.5.\n",
        "* Single LSTM, stacked LSTM and BiLSTM: We tested both LSTM and BiLSTM and found that BiLSTM performed best, with LSTM performing slightly better than GRU, probably because BiLSTM has better memory for longer sentence structures.\n",
        "* After Embedding the first layer we used BiLSTM to return sequences, then the second layer of 16 units of LSTM did not return sequences but only the final result, and finally a fully linked layer with a sigmoid activation function to output the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAJgtuqIqD8m"
      },
      "outputs": [],
      "source": [
        "# GRU code\n",
        "# model.add(GRU(units=32, return_sequences=True))\n",
        "# model.add(GRU(units=16, return_sequences=True))\n",
        "# model.add(GRU(units=4, return_sequences=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "7X2TMhweqD8m"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(lr=1e-3)"
      ],
      "metadata": {
        "id": "tPToqkhSP0nN"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "BxiEHtqlqD8m"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "bRaYlNQLqD8n",
        "outputId": "a691efd4-c479-48f4-ff1b-a8068a09a341",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 236, 300)          15000000  \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 236, 128)          186880    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 236, 32)           20608     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 16)                3136      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 15,210,641\n",
            "Trainable params: 210,641\n",
            "Non-trainable params: 15,000,000\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training "
      ],
      "metadata": {
        "id": "9bB4w7ssHH4A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "7Mobk-LHqD8n"
      },
      "outputs": [],
      "source": [
        "# Create a storage point for the weights\n",
        "path_checkpoint = 'sentiment_checkpoint.keras'\n",
        "checkpoint = ModelCheckpoint(filepath=path_checkpoint, monitor='val_loss',\n",
        "                                      verbose=1, save_weights_only=True,\n",
        "                                      save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "5f5fcwR7qD8n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8a931b6-b373-46c2-f440-bae75e6880fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unable to open file (unable to open file: name = 'sentiment_checkpoint.keras', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n"
          ]
        }
      ],
      "source": [
        "# Try to load a trained model\n",
        "try:\n",
        "    model.load_weights(path_checkpoint)\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gOk6uBsZd1fx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "UkDA3dOBqD8n"
      },
      "outputs": [],
      "source": [
        "# Define early stopping. If the validation loss does not improve within 5 epochs then stop training\n",
        "earlystopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "7hFmjYzBqD8o"
      },
      "outputs": [],
      "source": [
        "# Automatic learning rate reduction\n",
        "lr_reduction = ReduceLROnPlateau(monitor='val_loss',\n",
        "                                       factor=0.1, min_lr=1e-8, patience=0,\n",
        "                                       verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "PvSOKfxBqD8o"
      },
      "outputs": [],
      "source": [
        "# Define the callback function\n",
        "callbacks = [\n",
        "    earlystopping, \n",
        "    checkpoint,\n",
        "    lr_reduction\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "模型训练的过程中，val_loss的耐心在五次，如果连续五次epoch的val_loss都没有下降，就降低学习率以尝试改善loss值。如果容忍范围内的5次epoch降低学习率都不能改善结果，就执行early stopping终止训练. "
      ],
      "metadata": {
        "id": "XTXZd_Hwt-iM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "fGSxzYcEqD8o"
      },
      "outputs": [],
      "source": [
        "# # Start training \n",
        "# model.fit(X_train, y_train,\n",
        "#           validation_split=0.1, \n",
        "#           epochs=20,\n",
        "#           batch_size=128,\n",
        "#           callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_1 = model.fit(X_train, y_train,\n",
        "          validation_split=0.1, \n",
        "          epochs=20,\n",
        "          batch_size=128,\n",
        "          callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QFH9zzfAxcp",
        "outputId": "c712bae8-70dd-49d3-fdd0-334dbf76e8ec"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "26/26 [==============================] - 74s 2s/step - loss: 0.6046 - accuracy: 0.6676 - val_loss: 0.5501 - val_accuracy: 0.7222\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.55014, saving model to sentiment_checkpoint.keras\n",
            "Epoch 2/20\n",
            "26/26 [==============================] - 63s 2s/step - loss: 0.4331 - accuracy: 0.8173 - val_loss: 0.4085 - val_accuracy: 0.8139\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.55014 to 0.40853, saving model to sentiment_checkpoint.keras\n",
            "Epoch 3/20\n",
            "26/26 [==============================] - 62s 2s/step - loss: 0.3694 - accuracy: 0.8410 - val_loss: 0.3560 - val_accuracy: 0.8556\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.40853 to 0.35600, saving model to sentiment_checkpoint.keras\n",
            "Epoch 4/20\n",
            "26/26 [==============================] - 63s 2s/step - loss: 0.3786 - accuracy: 0.8429 - val_loss: 0.3226 - val_accuracy: 0.8917\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.35600 to 0.32264, saving model to sentiment_checkpoint.keras\n",
            "Epoch 5/20\n",
            "26/26 [==============================] - 62s 2s/step - loss: 0.3075 - accuracy: 0.8796 - val_loss: 0.3195 - val_accuracy: 0.8778\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.32264 to 0.31947, saving model to sentiment_checkpoint.keras\n",
            "Epoch 6/20\n",
            "26/26 [==============================] - 63s 2s/step - loss: 0.3222 - accuracy: 0.8685 - val_loss: 0.4162 - val_accuracy: 0.8361\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.31947\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 7/20\n",
            "26/26 [==============================] - 62s 2s/step - loss: 0.3009 - accuracy: 0.8787 - val_loss: 0.3005 - val_accuracy: 0.8944\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.31947 to 0.30049, saving model to sentiment_checkpoint.keras\n",
            "Epoch 8/20\n",
            "26/26 [==============================] - 63s 2s/step - loss: 0.2672 - accuracy: 0.8991 - val_loss: 0.2965 - val_accuracy: 0.8833\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.30049 to 0.29647, saving model to sentiment_checkpoint.keras\n",
            "Epoch 9/20\n",
            "26/26 [==============================] - 62s 2s/step - loss: 0.2519 - accuracy: 0.9065 - val_loss: 0.2950 - val_accuracy: 0.8889\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.29647 to 0.29501, saving model to sentiment_checkpoint.keras\n",
            "Epoch 10/20\n",
            "26/26 [==============================] - 63s 2s/step - loss: 0.2443 - accuracy: 0.9083 - val_loss: 0.2856 - val_accuracy: 0.8972\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.29501 to 0.28564, saving model to sentiment_checkpoint.keras\n",
            "Epoch 11/20\n",
            "26/26 [==============================] - 61s 2s/step - loss: 0.2411 - accuracy: 0.9083 - val_loss: 0.2816 - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.28564 to 0.28157, saving model to sentiment_checkpoint.keras\n",
            "Epoch 12/20\n",
            "26/26 [==============================] - 61s 2s/step - loss: 0.2369 - accuracy: 0.9105 - val_loss: 0.2893 - val_accuracy: 0.8861\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.28157\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Epoch 13/20\n",
            "26/26 [==============================] - 62s 2s/step - loss: 0.2300 - accuracy: 0.9145 - val_loss: 0.2840 - val_accuracy: 0.8944\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.28157\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "Epoch 14/20\n",
            "26/26 [==============================] - 61s 2s/step - loss: 0.2290 - accuracy: 0.9148 - val_loss: 0.2840 - val_accuracy: 0.8917\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.28157\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "Epoch 15/20\n",
            "26/26 [==============================] - 62s 2s/step - loss: 0.2290 - accuracy: 0.9148 - val_loss: 0.2840 - val_accuracy: 0.8917\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.28157\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
            "Epoch 16/20\n",
            "26/26 [==============================] - 61s 2s/step - loss: 0.2290 - accuracy: 0.9148 - val_loss: 0.2840 - val_accuracy: 0.8917\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.28157\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
            "Epoch 00016: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "使用keras保存历史准确率acc与loss值： \n",
        "\n",
        "https://blog.csdn.net/bluehatihati/article/details/100314601  \n",
        "  \n",
        "\n",
        "https://blog.csdn.net/weixin_36208314/article/details/113085566?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-1-113085566-blog-100314601.pc_relevant_multi_platform_whitelistv2&spm=1001.2101.3001.4242.2&utm_relevant_index=4  \n",
        "\n",
        "把前面的check point中的两个True改为False，试试结果。（不一定是必须的，因为两个True的情况下的结果仍然可以正常全部保存）\n",
        "\n"
      ],
      "metadata": {
        "id": "lQlYHkUaFmdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = history_1.history['val_loss']\n",
        "B = history_1.history['val_accuracy']"
      ],
      "metadata": {
        "id": "IDhVpASm1xae"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A1 = [0.5, 0.3, 0.6, 0.7]"
      ],
      "metadata": {
        "id": "0vWIaRqqEw2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "# plt.plot(A, label='val_loss', color='b')\n",
        "# plt.plot(A1, label='val_loss1', color='r')\n",
        "plt.plot(B, label='val_accuracy', color='r')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('val_accuracy')\n",
        "plt.legend()\n",
        "plt.title('Loss changes during network training')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "MldUfsLmEbua",
        "outputId": "8743d11e-f6d5-43b0-cb2f-d1811e00d77b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Test"
      ],
      "metadata": {
        "id": "R7ctB_aHG-hc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf5yKPeLqD8o"
      },
      "source": [
        "Firstly, we use model.evaluate( ) 输入test data(X_test)和test label(y_test)，输出损失和精确度.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.evaluate(X_test, y_test)\n",
        "print('Accuracy:{0:.2%}'.format(result[1]))"
      ],
      "metadata": {
        "id": "4Kx_ae-lHM4u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03b81eeb-6030-4872-c40c-a79f3e8c4339"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 2s 187ms/step - loss: 0.3118 - accuracy: 0.8750\n",
            "Accuracy:87.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then use model.predict( ) function to 输入test data(X_test)， 输出预测结果。并将预测结果和test label(y_test)进行对比，输出对应的confusion matrix heatmap。"
      ],
      "metadata": {
        "id": "3VNx_D3UHNbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Then, load the saved model, and evaluate it on the test data'''\n",
        "# evaluate on the test data\n",
        "test_pred = model.predict(X_test) \n",
        "# print(test_pred)\n",
        "# print(test_pred.shape)"
      ],
      "metadata": {
        "id": "n9enOnaOyfyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = model.predict(X_test) "
      ],
      "metadata": {
        "id": "BOHkbdlY23Gs"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix (sn.heatmap) 待删\n",
        "A = []\n",
        "for i in test_pred:\n",
        "  if i >= 0.5:\n",
        "    A.append(1)\n",
        "  else:\n",
        "    A.append(0)\n",
        "# cm = confusion_matrix(y_test,A,labels=[0,1])  # get confusion matrix\n",
        "# df_cm = pd.DataFrame(cm)  # convert the confusion matrix to dataframe\n",
        "# ax = sn.heatmap(df_cm,annot=True,fmt='.20g',cmap=\"Greens\")  # annot = True -> Show numbers\n",
        "# ax.set_title('confusion matrix')\n",
        "# ax.set_xlabel('predict')\n",
        "# ax.set_ylabel('true')"
      ],
      "metadata": {
        "id": "ma4iQNY03sSV"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix\n",
        "def confusion_matrix_heatmap(y_test, preds):\n",
        "    \"\"\"Function to plot a confusion matrix\"\"\"\n",
        "    labels = list(set(y_test))   # get the labels in the y_test\n",
        "    # print(labels)\n",
        "    # cm = confusion_matrix(y_test, preds, labels)\n",
        "    cm = confusion_matrix(y_test,A,labels=[0,1])  # get confusion matrix\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(cm)\n",
        "    plt.title('Confusion matrix')\n",
        "    fig.colorbar(cax)\n",
        "    ax.set_xticks(np.arange(len(labels)))\n",
        "    ax.set_yticks(np.arange(len(labels)))\n",
        "    ax.set_xticklabels( labels, rotation=45)\n",
        "    ax.set_yticklabels( labels)\n",
        "\n",
        "    for i in range(len(cm)):\n",
        "        for j in range(len(cm)):\n",
        "            text = ax.text(j, i, cm[i, j],\n",
        "                           ha=\"center\", va=\"center\", color=\"red\")\n",
        "\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    #fig.tight_layout()\n",
        "    # # fix for mpl bug that cuts off top/bottom of seaborn viz:\n",
        "    # b, t = plt.ylim() # discover the values for bottom and top\n",
        "    # b += 0.5 # Add 0.5 to the bottom\n",
        "    # t -= 0.5 # Subtract 0.5 from the top\n",
        "    # plt.ylim(b, t) # update the ylim(bottom, top) values\n",
        "    plt.savefig('hi')\n",
        "    plt.show() # ta-da!\n",
        "\n",
        "\n",
        "confusion_matrix_heatmap(y_test, A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "dx1AJ2lW_G3a",
        "outputId": "d05d5e7e-c49a-4db8-cfab-2c6c567da722"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, We define a new prediction function to predict the label of the custom input text. The results show that the model is accurate for negative sentences and simple logical structures."
      ],
      "metadata": {
        "id": "ws_uCSrXmzg4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "NHOoWluNqD8p"
      },
      "outputs": [],
      "source": [
        "def predict_sentiment(text):\n",
        "    print(text, end=\" \")\n",
        "    # remove punctuation\n",
        "    text = re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&*（）]+\", \"\",text)\n",
        "    # word segmentation\n",
        "    cut = jieba.cut(text)\n",
        "    cut_list = [ i for i in cut ]\n",
        "    # tokenize\n",
        "    for i, word in enumerate(cut_list):\n",
        "        try:\n",
        "            # cut_list[i] = cn_model.vocab[word].index\n",
        "            cut_list[i] = cn_model.key_to_index[word]\n",
        "            if cut_list[i] >= 50000:\n",
        "                cut_list[i] = 0\n",
        "        except KeyError:\n",
        "            cut_list[i] = 0\n",
        "    # padding\n",
        "    tokens_pad = pad_sequences([cut_list], maxlen=max_tokens,\n",
        "                           padding='pre', truncating='pre')\n",
        "    # predict \n",
        "    result = model.predict(x=tokens_pad)\n",
        "    coef = result[0][0]\n",
        "    if coef >= 0.5:\n",
        "        # print('-> prediction: positive','-> output=%.2f'%coef)\n",
        "        print('-> output=%.2f'%coef, '-> positive')\n",
        "    else:\n",
        "        print('-> output=%.2f'%coef, '-> negative')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "crkPH1PuqD8p",
        "outputId": "209e36df-4feb-4186-880a-b83024ab8b0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "酒店设施不是新的，服务态度很不好 -> output=0.33 -> negative\n",
            "酒店卫生条件非常不好 -> output=0.31 -> negative\n",
            "床铺非常舒适 -> output=0.74 -> positive\n",
            "房间很凉，不给开暖气 -> output=0.32 -> negative\n",
            "房间很凉爽，空调冷气很足 -> output=0.76 -> positive\n",
            "酒店环境不好，住宿体验很不好 -> output=0.14 -> negative\n",
            "房间隔音不到位 -> output=0.33 -> negative\n",
            "晚上回来发现没有打扫卫生 -> output=0.40 -> negative\n",
            "因为过节所以要我临时加钱，比团购的价格贵 -> output=0.09 -> negative\n"
          ]
        }
      ],
      "source": [
        "test_list = [\n",
        "    '酒店设施不是新的，服务态度很不好',\n",
        "    '酒店卫生条件非常不好',\n",
        "    '床铺非常舒适',\n",
        "    '房间很凉，不给开暖气',\n",
        "    '房间很凉爽，空调冷气很足',\n",
        "    '酒店环境不好，住宿体验很不好',\n",
        "    '房间隔音不到位' ,\n",
        "    '晚上回来发现没有打扫卫生',\n",
        "    '因为过节所以要我临时加钱，比团购的价格贵'\n",
        "]\n",
        "for text in test_list:\n",
        "    predict_sentiment(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Error Analysis "
      ],
      "metadata": {
        "id": "679sGH3AG5ap"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av_ceAdrqD8p"
      },
      "source": [
        "Through our analysis, we find that the meaning of the misclassified text is mostly ambiguous, and even humans can not easily determine the polarity. For example, this sentence with index 305 seems to have no element of satisfaction at all, but this example rating is marked as positive in the training sample, and the prediction of a negative rating made by our model seems reasonable."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "首先让已经训练好的模型在400条测试集上进行实验，得到相应的测试集预测标签y_pred,然后将其与测试集的真实标签y_test进行对比。并统计出所有分类错误的false positive和false negative样本索引。并在最后针对FP和FN分别进行详细的错误分析。 \n",
        "\n",
        "false positive samples: 预测你是负向，但实际不是负向(pred=0, label=1)  \n",
        "false negative samples: 预测你不是负向，但实际是负向(pred=1, label=0)"
      ],
      "metadata": {
        "id": "MeUEneDrw4KZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "JmlVKiYkqD8p"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred = y_pred.T[0]\n",
        "y_pred = [1 if p>= 0.5 else 0 for p in y_pred]\n",
        "y_pred = np.array(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "dE_-OBr0qD8p"
      },
      "outputs": [],
      "source": [
        "y_actual = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F_P = []\n",
        "F_N = []\n",
        "\n",
        "for i in range(400):\n",
        "  if y_pred[i]==0 and y_actual[i]==1:\n",
        "    F_P.append(i)\n",
        "  if y_pred[i]==1 and y_actual[i]==0:\n",
        "    F_N.append(i)\n",
        "\n",
        "print('The indexes of false positive samples are as follows:')\n",
        "print(F_P)\n",
        "print(\" \")\n",
        "print('The indexes of false negative samples are as follows:')\n",
        "print(F_N)\n",
        "print(\" \")\n",
        "print('The total number of misclassified samples is:')\n",
        "print(len(F_P+F_N))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-O4jqG9rDcJ",
        "outputId": "1dabcb1b-bd3a-4b49-b97e-fed8b98ac2d2"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The indexes of false positive samples are as follows:\n",
            "[1, 30, 73, 80, 81, 101, 123, 127, 130, 189, 207, 211, 223, 228, 238, 246, 253, 267, 286, 297, 305, 335, 349, 365, 373, 391]\n",
            " \n",
            "The indexes of false negative samples are as follows:\n",
            "[5, 14, 15, 21, 42, 59, 72, 87, 128, 148, 182, 218, 244, 257, 258, 275, 283, 285, 302, 311, 342, 347, 352, 368]\n",
            " \n",
            "The total number of misclassified samples is:\n",
            "50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Output False Positive Samples (prediction=0, label=1)**"
      ],
      "metadata": {
        "id": "WGseScFcSbMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly select five false positive samples from the F_P list. \n",
        "FP_index = random.sample(F_P, 5)"
      ],
      "metadata": {
        "id": "ymMVxEFf4d-f"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# False Positive Sample 01: \n",
        "print('False Positive Sample 01:')\n",
        "idx = FP_index[0]\n",
        "reverse_tokens(X_test[idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "VAanTNdEyHCq",
        "outputId": "4bc6272f-bc81-4758-8030-bfb2ba737d0e"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False Positive Sample 01:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'                                                                                                                                                                                                         入住的时候 在哪里?房间里的花盆特别象90年代初期的田园花盆极为难看更可怕的是入住的时候门口不管客人照常 范围清洁'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# False Positive Sample 02: \n",
        "print('False Positive Sample 02:')\n",
        "idx = FP_index[1]\n",
        "reverse_tokens(X_test[idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "Tz70lIA94YcU",
        "outputId": "d7a31172-87df-424d-8dae-b0187007d54e"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False Positive Sample 02:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'                                                                                                                                                                                         酒店 房间硬件设施还是不错的但是餐厅实在太差上菜非常慢价格 质量差86元2 的香煎银鳕鱼居然是臭的叫来餐厅经理品尝了半天不吭声最后竟然然颠倒黑白地说不臭实在不能容忍'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# False Positive Sample 03: \n",
        "print('False Positive Sample 03:')\n",
        "idx = FP_index[2]\n",
        "reverse_tokens(X_test[idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "9l-tRFpT4Yj7",
        "outputId": "9f49de91-b0f4-4e1a-dd10-fbec105fd484"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False Positive Sample 03:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'                                                                                                                                                                                                       房间够大因为带了孩子定的是  了不要35 的时候其他楼层的没房间了前台主动安排大床房免费加了 床态度 的'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# False Positive Sample 04: \n",
        "print('False Positive Sample 04:')\n",
        "idx = FP_index[3]\n",
        "reverse_tokens(X_test[idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "HJC6K83o4YqF",
        "outputId": "a4171f8e-76f8-4fc5-93fd-c44beb69a1f4"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False Positive Sample 04:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'                                                                                                                                                                                               好当时看到有人评价说什么 多我还心有余悸呢结果好的不得了吗哪里有电话我们自己人打电话  仔细核对身份呢而且房间也好服务也非常的好真的是徐州 的酒店'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# False Positive Sample 05: \n",
        "print('False Positive Sample 05:')\n",
        "idx = FP_index[4]\n",
        "reverse_tokens(X_test[idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "emhjJFvb4YwM",
        "outputId": "4c98a803-ce97-440f-e70a-4aa90e03463c"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False Positive Sample 05:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'                                                                                                                                                                                                        没有想象的离西湖近年轻人走走也得10-15分钟因为窗不是面对西湖的所以景基本看不到西湖要把头 勉强看到商业街远处的尽头是湖面'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "****Output False Negative Samples (prediction=1, label=0)****"
      ],
      "metadata": {
        "id": "upw5oZkAyHXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly select five false negative samples from the F_N list. \n",
        "FN_index = random.sample(F_N, 5)"
      ],
      "metadata": {
        "id": "T5QgTmNLyHeD"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# False Positive Sample 01: \n",
        "print('False Negative Sample 01:')\n",
        "idx = FN_index[0]\n",
        "reverse_tokens(X_test[idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "idFj1-l6yHgw",
        "outputId": "667d2849-72c8-4be1-d88c-60b358d5425a"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False Negative Sample 01:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'                                                                                                                                                           在胡同里不过还算好找房价便宜 简单但还比较干净离  步行都可以出 就有小吃店如果 火车站近可以选这补充点评2008年4月21日：之前给的点评错误因为看错宾馆名字 和平宾馆这家酒店给我 虽然地段好就靠 但退房速度慢房间隔音不好有味道看上去不干净下次不会去了'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# False Positive Sample 02: \n",
        "print('False Negative Sample 02:')\n",
        "idx = FN_index[1]\n",
        "reverse_tokens(X_test[idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "mt00MWPcyHjM",
        "outputId": "1cee7edb-6891-4589-9863-0977240c3a9a"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False Negative Sample 02:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'                                                                                                                                                                                                                               而去我的评价：地段差服务 硬件还可以'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# False Positive Sample 03: \n",
        "print('False Negative Sample 03:')\n",
        "idx = FN_index[2]\n",
        "reverse_tokens(X_test[idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "sHfFtnlp5ynE",
        "outputId": "d206aa40-bf78-46ab-a22e-1dd3c1313326"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False Negative Sample 03:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'                                                                                                                                                                                                                            感觉一般就是各方面都一般在 这种地方住住还是可以的'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# False Positive Sample 04: \n",
        "print('False Negative Sample 04:')\n",
        "idx = FN_index[3]\n",
        "reverse_tokens(X_test[idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "phdgo3825yro",
        "outputId": "2fa5fdee-27d5-4a30-f6b7-770d4bd6b486"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False Negative Sample 04:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'                                                                                                                                                                              地理位置还不错到哪里都比较方便但是服务不象是 集团管理的比较差下午睡了 并洗了一个澡本来想让酒店再来打扫一下所以打开了请打扫的服务灯可是到晚上回酒店发现打扫得服务灯被关掉了而房间还是没有打扫过'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# False Positive Sample 05: \n",
        "print('False Negative Sample 05:')\n",
        "idx = FN_index[4]\n",
        "reverse_tokens(X_test[idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "UL_lZFvc5ywD",
        "outputId": "74ebcf21-d982-4b2f-efe1-17fa71a44435"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False Negative Sample 05:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'                                                                                                                                                                                          特价房相当的吵临近高价桥晚上 拉不过在背面的房间倒还不错价格也很有吸引力就是房间很旧服务员态度一般而且还很忙入住和退房都等了很久差不多10-30分钟才能搞定'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "L9nsi8ZsaXHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TnSVpaKBaXRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "这里提出一点儿改进措施，即情感细粒度分析。原先只有两类正向和负向，我们可以更细致地进行区分，比如加上‘中立’这个情感态度。只是建议，因为数据集的label只有0和1两类，所以如果要进行更细腻的情感分析，可能需要修改新的数据集，这是一个不小的工作量。后期可以考虑如何在不修改原始数据集的情况下进行此改进。 \n",
        "\n",
        "可以现在github上找一下是否有更高质量的数据集。"
      ],
      "metadata": {
        "id": "bnUrnWP38kGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dHHUOB1ueb-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9Ivbw7XI5y0e"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}